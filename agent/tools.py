# -*- coding: utf-8 -*-
"""
ğŸ¤ TTS Agent å·¥å…·åŒ…

æä¾› LangChain Tool æ ¼å¼çš„ TTS å·¥å…·
"""

import os
import uuid
import tempfile
from pathlib import Path
from typing import Optional, List, Dict, Any

os.environ.setdefault("LANGCHAIN_TRACING_V2", "false")
os.environ.setdefault("LANGSMITH_TRACING", "false")

try:
    from langchain_core.tools import tool
except ImportError:
    def tool(func=None, **_kwargs):
        def decorator(f):
            return f
        return decorator if func is None else decorator(func)

from dotenv import load_dotenv
load_dotenv()


# é»˜è®¤è¾“å‡ºç›®å½•
DEFAULT_OUTPUT_DIR = os.path.join(tempfile.gettempdir(), "tts_agent_output")
os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)


def _get_resource_id(voice_id: str) -> str:
    """æ ¹æ®éŸ³è‰² ID è‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„èµ„æº ID"""
    voice_lower = voice_id.lower()
    
    if voice_lower.startswith("icl_"):
        return "seed-icl-1.0"
    
    if "uranus" in voice_lower:
        return "seed-tts-2.0"
    
    if voice_lower.startswith("saturn_"):
        return "seed-tts-2.0"
    
    if "_saturn_bigtts" in voice_lower:
        return "seed-tts-2.0"
    
    return "seed-tts-1.0"


def _get_tts_service(voice_id: str = None):
    """å»¶è¿Ÿå¯¼å…¥ TTS æœåŠ¡"""
    from backend.services import DoubaoTTSService
    from backend.models import TTSConfig
    
    resource_id = _get_resource_id(voice_id) if voice_id else "seed-tts-1.0"
    return DoubaoTTSService(resource_id=resource_id), TTSConfig


@tool
def tts_preview(
    text: str,
    voice_id: str,
    output_dir: Optional[str] = None,
) -> Dict[str, Any]:
    """
    TTS è¯•å¬å·¥å…· - ç”Ÿæˆå•å¥è¯­éŸ³è¯•å¬éŸ³é¢‘
    
    Args:
        text: è¦åˆæˆçš„æ–‡æœ¬
        voice_id: éŸ³è‰²ID
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        åŒ…å« success, audio_path, duration_ms, error çš„å­—å…¸
    """
    try:
        service, TTSConfig = _get_tts_service(voice_id)
        config = TTSConfig(voice_type=voice_id)
        
        out_dir = output_dir or DEFAULT_OUTPUT_DIR
        os.makedirs(out_dir, exist_ok=True)
        
        filename = f"preview_{uuid.uuid4().hex[:8]}.mp3"
        output_path = os.path.join(out_dir, filename)
        
        result = service.synthesize_auto(text=text, config=config, output_path=output_path)
        
        if result.success:
            return {
                "success": True,
                "audio_path": result.audio_path or output_path,
                "duration_ms": result.duration_ms,
            }
        else:
            return {"success": False, "error": result.error_message or "åˆæˆå¤±è´¥"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@tool
def tts_synthesize(
    text: str,
    voice_id: str,
    output_path: Optional[str] = None,
) -> Dict[str, Any]:
    """
    TTS åˆæˆå·¥å…· - åˆæˆå•å¥è¯­éŸ³éŸ³é¢‘
    
    Args:
        text: è¦åˆæˆçš„æ–‡æœ¬
        voice_id: éŸ³è‰²ID
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    
    Returns:
        åŒ…å« success, audio_path, duration_ms, error çš„å­—å…¸
    """
    try:
        service, TTSConfig = _get_tts_service(voice_id)
        config = TTSConfig(voice_type=voice_id)
        
        if not output_path:
            os.makedirs(DEFAULT_OUTPUT_DIR, exist_ok=True)
            filename = f"synth_{uuid.uuid4().hex[:8]}.mp3"
            output_path = os.path.join(DEFAULT_OUTPUT_DIR, filename)
        
        result = service.synthesize_auto(text=text, config=config, output_path=output_path)
        
        if result.success:
            return {
                "success": True,
                "audio_path": result.audio_path or output_path,
                "duration_ms": result.duration_ms,
            }
        else:
            return {"success": False, "error": result.error_message or "åˆæˆå¤±è´¥"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@tool
def tts_synthesize_batch(
    items: List[Dict[str, Any]],
    output_dir: Optional[str] = None,
    use_multi_turn: bool = True,
    context_window: int = 3,
) -> Dict[str, Any]:
    """
    TTS æ‰¹é‡åˆæˆå·¥å…· - æ‰¹é‡åˆæˆå¤šå¥è¯­éŸ³éŸ³é¢‘
    
    Args:
        items: åˆæˆé¡¹åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        use_multi_turn: æ˜¯å¦å¯ç”¨å¤šè½®ä¸Šä¸‹æ–‡
        context_window: ä¸Šä¸‹æ–‡çª—å£å¤§å°
    
    Returns:
        åŒ…å« success, results, total, succeeded, failed çš„å­—å…¸
    """
    try:
        out_dir = output_dir or DEFAULT_OUTPUT_DIR
        os.makedirs(out_dir, exist_ok=True)
        
        if use_multi_turn:
            return _synthesize_batch_multi_turn(items, out_dir)
        else:
            return _synthesize_batch_legacy(items, out_dir)
            
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "total": len(items),
            "succeeded": 0,
            "failed": len(items),
        }


def _synthesize_batch_multi_turn(items: List[Dict[str, Any]], out_dir: str) -> Dict[str, Any]:
    """ä½¿ç”¨ MultiTurnTTSSession è¿›è¡Œæ‰¹é‡åˆæˆ"""
    from backend.services import DoubaoTTSService, MultiTurnTTSSession
    
    tts = DoubaoTTSService()
    session = MultiTurnTTSSession(tts, output_dir=out_dir)
    
    results = []
    succeeded = 0
    failed = 0
    
    for i, item in enumerate(items):
        text = item.get("text", "")
        voice_id = item.get("voice_id", "")
        instruction = item.get("instruction", "")
        emotion = item.get("emotion")
        emotion_scale = item.get("emotion_scale")
        filename = item.get("filename", f"dialogue_{i+1:03d}.mp3")
        reset_context = item.get("reset_context", False)
        
        if not text or not voice_id:
            results.append({
                "index": i,
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦å‚æ•° text æˆ– voice_id",
            })
            failed += 1
            continue
        
        if reset_context:
            session.reset_context()
        
        emotion_instruction = _build_emotion_instruction(instruction) if instruction else None
        
        result = session.synthesize(
            text=text,
            voice_type=voice_id,
            emotion_instruction=emotion_instruction,
            emotion=emotion,
            emotion_scale=emotion_scale,
            output_filename=filename,
        )
        
        if result.success:
            results.append({
                "index": i,
                "success": True,
                "audio_path": result.audio_path,
                "duration_ms": result.duration_ms,
            })
            succeeded += 1
        else:
            results.append({
                "index": i,
                "success": False,
                "error": result.error_message or "åˆæˆå¤±è´¥",
            })
            failed += 1
    
    return {
        "success": failed == 0,
        "results": results,
        "total": len(items),
        "succeeded": succeeded,
        "failed": failed,
        "output_dir": out_dir,
        "context_depth": session.v2_context_depth,
    }


def _synthesize_batch_legacy(items: List[Dict[str, Any]], out_dir: str) -> Dict[str, Any]:
    """åŸé€»è¾‘ï¼šç‹¬ç«‹åˆæˆ"""
    from backend.services import DoubaoTTSService
    from backend.models import TTSConfig
    
    results = []
    succeeded = 0
    failed = 0
    service_cache = {}
    
    for i, item in enumerate(items):
        text = item.get("text", "")
        instruction = item.get("instruction", "")
        voice_id = item.get("voice_id", "")
        filename = item.get("filename", f"dialogue_{i+1:03d}.mp3")
        output_path = os.path.join(out_dir, filename)
        
        if not text or not voice_id:
            results.append({
                "index": i,
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦å‚æ•° text æˆ– voice_id",
            })
            failed += 1
            continue
        
        resource_id = _get_resource_id(voice_id)
        if resource_id not in service_cache:
            service_cache[resource_id] = DoubaoTTSService(resource_id=resource_id)
        service = service_cache[resource_id]
        
        config = TTSConfig(voice_type=voice_id)
        context_texts = _build_context_legacy(instruction)
        
        result = service.synthesize(
            text=text,
            config=config,
            output_path=output_path,
            context_texts=context_texts,
        )
        
        if result.success:
            results.append({
                "index": i,
                "success": True,
                "audio_path": result.audio_path or output_path,
                "duration_ms": result.duration_ms,
            })
            succeeded += 1
        else:
            results.append({
                "index": i,
                "success": False,
                "error": result.error_message or "åˆæˆå¤±è´¥",
            })
            failed += 1
    
    return {
        "success": failed == 0,
        "results": results,
        "total": len(items),
        "succeeded": succeeded,
        "failed": failed,
        "output_dir": out_dir,
    }


def _build_emotion_instruction(instruction: str) -> Optional[str]:
    """å°† instruction è½¬æ¢ä¸º2.0çš„æƒ…ç»ªæŒ‡ä»¤æ ¼å¼"""
    if not instruction:
        return None
    
    clean = instruction.strip()
    clean = clean.lstrip('[').lstrip('#').lstrip('ï¼ƒ')
    clean = clean.rstrip(']')
    clean = clean.strip()
    
    if not clean:
        return None
    
    if not clean.endswith('è¯') and not clean.endswith('?') and not clean.endswith('ï¼Ÿ'):
        clean = clean.rstrip('è¯´')
        clean = f"è¯·{clean}è¯´è¯"
    
    return clean


def _build_context_legacy(instruction: str) -> Optional[list]:
    """åŸé€»è¾‘ï¼šæ„å»º context_texts å‚æ•°"""
    result = _build_emotion_instruction(instruction)
    return [result] if result else None


@tool
def audio_merge(
    audio_paths: List[str],
    output_path: str,
    gap_ms: int = 500,
) -> Dict[str, Any]:
    """
    éŸ³é¢‘åˆå¹¶å·¥å…· - å°†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ª
    
    Args:
        audio_paths: è¦åˆå¹¶çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: åˆå¹¶åçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
        gap_ms: ç‰‡æ®µä¹‹é—´çš„é—´éš”æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    
    Returns:
        åŒ…å« success, merged_audio_path, total_duration_ms, error çš„å­—å…¸
    """
    try:
        if not audio_paths:
            return {"success": False, "error": "éŸ³é¢‘è·¯å¾„åˆ—è¡¨ä¸ºç©º"}

        for path in audio_paths:
            if not os.path.exists(path):
                return {"success": False, "error": f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {path}"}

        os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)

        suffix = Path(output_path).suffix.lower()
        if suffix == ".mp3":
            import shutil
            import subprocess

            ffmpeg = shutil.which("ffmpeg")
            if ffmpeg:
                try:
                    with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False, encoding="utf-8") as f:
                        concat_list_path = f.name
                        for p in audio_paths:
                            safe_path = p.replace("'", "'\\''")
                            f.write(f"file '{safe_path}'\n")

                    proc = subprocess.run(
                        [ffmpeg, "-y", "-hide_banner", "-loglevel", "error", "-f", "concat", "-safe", "0", "-i", concat_list_path, "-c", "copy", output_path],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True,
                        check=False,
                    )
                    if proc.returncode == 0 and os.path.exists(output_path):
                        return {
                            "success": True,
                            "merged_audio_path": output_path,
                            "total_duration_ms": None,
                        }
                finally:
                    try:
                        os.remove(concat_list_path)
                    except Exception:
                        pass

            def _strip_id3v2(data: bytes) -> bytes:
                if len(data) < 10 or data[:3] != b"ID3":
                    return data
                size_bytes = data[6:10]
                tag_size = 0
                for b in size_bytes:
                    tag_size = (tag_size << 7) | (b & 0x7F)
                start = 10 + tag_size
                return data[start:] if start < len(data) else b""

            with open(output_path, "wb") as out_f:
                for i, p in enumerate(audio_paths):
                    with open(p, "rb") as in_f:
                        data = in_f.read()
                    if i > 0:
                        data = _strip_id3v2(data)
                    out_f.write(data)

            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                return {
                    "success": True,
                    "merged_audio_path": output_path,
                    "total_duration_ms": None,
                }
            return {"success": False, "error": "åˆå¹¶å¤±è´¥ï¼šæ— æ³•ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"}

        from pydub import AudioSegment

        merged = AudioSegment.from_file(audio_paths[0])
        gap = AudioSegment.silent(duration=gap_ms)

        for path in audio_paths[1:]:
            audio = AudioSegment.from_file(path)
            merged = merged + gap + audio

        merged.export(output_path, format=suffix.lstrip(".") or "mp3")

        return {
            "success": True,
            "merged_audio_path": output_path,
            "total_duration_ms": len(merged),
        }
    except ImportError:
        return {"success": False, "error": "éœ€è¦å®‰è£… pydub åº“ï¼špip install pydub"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@tool
def get_voice_list(
    gender: Optional[str] = None,
    category: Optional[str] = None,
    limit: int = 20,
) -> Dict[str, Any]:
    """
    è·å–å¯ç”¨éŸ³è‰²åˆ—è¡¨
    
    Args:
        gender: æ€§åˆ«è¿‡æ»¤
        category: ç±»åˆ«è¿‡æ»¤
        limit: è¿”å›çš„æœ€å¤§æ•°é‡
    
    Returns:
        åŒ…å« success, voices, total çš„å­—å…¸
    """
    voices = [
        {"voice_id": "zh_female_vv_uranus_bigtts", "name": "Vivi 2.0", "gender": "female", "category": "2.0é€šç”¨", "desc": "å¹´è½»å¥³æ€§ï¼Œæ¸…æ™°è‡ªç„¶"},
        {"voice_id": "zh_female_xiaohe_uranus_bigtts", "name": "å°ä½• 2.0", "gender": "female", "category": "2.0é€šç”¨", "desc": "æ¸©æŸ”äº²åˆ‡"},
        {"voice_id": "zh_male_m191_uranus_bigtts", "name": "äº‘èˆŸ 2.0", "gender": "male", "category": "2.0é€šç”¨", "desc": "æˆç†Ÿç”·æ€§"},
        {"voice_id": "zh_male_taocheng_uranus_bigtts", "name": "å°å¤© 2.0", "gender": "male", "category": "2.0é€šç”¨", "desc": "å¹´è½»ç”·æ€§"},
        {"voice_id": "zh_female_gaolengyujie_emo_v2_mars_bigtts", "name": "é«˜å†·å¾¡å§", "gender": "female", "category": "å¤šæƒ…æ„Ÿ", "desc": "å†·è‰³é«˜å‚²"},
        {"voice_id": "zh_female_tianxinxiaomei_emo_v2_mars_bigtts", "name": "ç”œå¿ƒå°ç¾", "gender": "female", "category": "å¤šæƒ…æ„Ÿ", "desc": "ç”œç¾å¯çˆ±"},
        {"voice_id": "zh_male_lengkugege_emo_v2_mars_bigtts", "name": "å†·é…·å“¥å“¥", "gender": "male", "category": "å¤šæƒ…æ„Ÿ", "desc": "å†·é…·å¸…æ°”"},
        {"voice_id": "zh_male_aojiaobazong_emo_v2_mars_bigtts", "name": "å‚²å¨‡éœ¸æ€»", "gender": "male", "category": "å¤šæƒ…æ„Ÿ", "desc": "å‚²å¨‡éœ¸æ°”"},
        {"voice_id": "saturn_zh_female_keainvsheng_tob", "name": "å¯çˆ±å¥³ç”Ÿ", "gender": "female", "category": "è§’è‰²æ‰®æ¼”", "desc": "å¯çˆ±ç”œç¾"},
        {"voice_id": "saturn_zh_male_shuanglangshaonian_tob", "name": "çˆ½æœ—å°‘å¹´", "gender": "male", "category": "è§’è‰²æ‰®æ¼”", "desc": "é˜³å…‰çˆ½æœ—"},
    ]
    
    result = voices
    if gender:
        result = [v for v in result if v["gender"] == gender]
    if category:
        result = [v for v in result if v["category"] == category]
    
    return {
        "success": True,
        "voices": result[:limit],
        "total": len(result),
    }


# å·¥å…·é›†åˆ
PREVIEW_TOOLS = [tts_preview, get_voice_list]
SYNTHESIS_TOOLS = [tts_synthesize, tts_synthesize_batch, audio_merge]
TTS_TOOLS = PREVIEW_TOOLS + SYNTHESIS_TOOLS
