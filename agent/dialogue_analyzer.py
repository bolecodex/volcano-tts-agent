# -*- coding: utf-8 -*-
"""
ğŸ¤ DialogueAnalyzerAgent - å¯¹è¯åˆ†æ Agent

è´Ÿè´£åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«è¾“å…¥ç±»å‹ï¼Œç”Ÿæˆæ ‡å‡†åŒ–çš„å¯¹è¯åˆ—è¡¨
"""

import os
import re
import json
import uuid
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable

os.environ.setdefault("LANGCHAIN_TRACING_V2", "false")
os.environ.setdefault("LANGSMITH_TRACING", "false")

from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.tools import tool

from .prompts import DIALOGUE_ANALYZER_SYSTEM_PROMPT
from .models import DialogueItem, InputType, parse_dialogue_list

logger = logging.getLogger(__name__)


def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
    """ä»æ–‡æœ¬ä¸­æå– JSON å¯¹è±¡"""
    if not text:
        return None
    
    try:
        return json.loads(text.strip())
    except json.JSONDecodeError:
        pass
    
    code_block_pattern = r'```(?:json)?\s*\n?([\s\S]*?)\n?```'
    matches = re.findall(code_block_pattern, text)
    for match in matches:
        try:
            return json.loads(match.strip())
        except json.JSONDecodeError:
            continue
    
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1 and end > start:
        try:
            return json.loads(text[start:end + 1])
        except json.JSONDecodeError:
            pass
    
    start = text.find('[')
    end = text.rfind(']')
    if start != -1 and end != -1 and end > start:
        try:
            return {"dialogue_list": json.loads(text[start:end + 1])}
        except json.JSONDecodeError:
            pass
    
    return None


@tool
def save_dialogue_result(dialogue_list_json: str) -> str:
    """
    ä¿å­˜å¯¹è¯åˆ†æç»“æœ
    
    Args:
        dialogue_list_json: JSON æ ¼å¼çš„å¯¹è¯åˆ—è¡¨
    
    Returns:
        ä¿å­˜ç»“æœç¡®è®¤
    """
    try:
        data = json.loads(dialogue_list_json)
        
        if isinstance(data, dict) and "dialogue_list" in data:
            dialogue_list = data["dialogue_list"]
            input_type = data.get("input_type", "unknown")
            
            valid_items = []
            for item in dialogue_list:
                if isinstance(item, dict) and "character" in item and "text" in item:
                    valid_items.append(item)
            
            if valid_items:
                return json.dumps({
                    "success": True,
                    "message": f"âœ… å·²ä¿å­˜ {len(valid_items)} æ¡å¯¹è¯è®°å½•",
                    "input_type": input_type,
                    "count": len(valid_items),
                    "data": data,
                }, ensure_ascii=False)
            else:
                return json.dumps({
                    "success": False,
                    "error": "å¯¹è¯åˆ—è¡¨ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ¡ç›®",
                }, ensure_ascii=False)
        
        elif isinstance(data, list):
            return json.dumps({
                "success": True,
                "message": f"âœ… å·²ä¿å­˜ {len(data)} æ¡å¯¹è¯è®°å½•",
                "input_type": "unknown",
                "count": len(data),
                "data": {"dialogue_list": data},
            }, ensure_ascii=False)
        
        else:
            return json.dumps({
                "success": False,
                "error": "æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ç¡®ä¿åŒ…å« dialogue_list å­—æ®µ",
            }, ensure_ascii=False)
            
    except json.JSONDecodeError as e:
        return json.dumps({
            "success": False,
            "error": f"JSON è§£æå¤±è´¥: {e}",
        }, ensure_ascii=False)


DIALOGUE_ANALYZER_TOOLS = [save_dialogue_result]


class DialogueAnalyzerAgent:
    """å¯¹è¯åˆ†æ Agent"""
    
    def __init__(
        self,
        model: Optional[str] = None,
        checkpointer=None,
        verbose: bool = True,
        context_file: Optional[str] = None,
    ):
        self.verbose = verbose
        self.model_name = model
        
        self.context_content = ""
        if context_file and os.path.exists(context_file):
            with open(context_file, "r", encoding="utf-8") as f:
                self.context_content = f.read()
        
        # åˆ›å»º LLM
        from .llm_config import LLMConfig, get_llm_config
        base_config = get_llm_config()
        
        streaming_config = LLMConfig(
            provider=base_config.provider,
            model=model or base_config.model,
            api_key=base_config.api_key,
            base_url=base_config.base_url,
            temperature=0.7,
            max_tokens=65536,
            streaming=True,
            extra_params=base_config.extra_params,
        )
        self.llm = streaming_config.create_llm()
        
        if checkpointer is None:
            checkpointer = InMemorySaver()
        self.checkpointer = checkpointer
        
        self._agent = None
        self._create_agent()
        
        self._thread_id = f"dialogue_session_{uuid.uuid4().hex[:8]}"
        self._last_result: Optional[Dict[str, Any]] = None
    
    def _log(self, message: str):
        if self.verbose:
            print(message)
    
    def _build_system_prompt(self) -> str:
        prompt = DIALOGUE_ANALYZER_SYSTEM_PROMPT
        if self.context_content:
            prompt += "\n\n## å‚è€ƒï¼šè±†åŒ…2.0æŒ‡ä»¤æ ¼å¼\n\n"
            prompt += self.context_content[:3000] + "\n..."
        return prompt
    
    def _create_agent(self):
        try:
            from langgraph.prebuilt import create_react_agent
            
            self._agent = create_react_agent(
                model=self.llm,
                tools=DIALOGUE_ANALYZER_TOOLS,
                prompt=self._build_system_prompt(),
                checkpointer=self.checkpointer,
            )
            self._log("ğŸš€ å¯¹è¯åˆ†æ Agent å·²å¯åŠ¨")
        except ImportError as e:
            self._log(f"âš ï¸ æ— æ³•å¯¼å…¥ langgraph: {e}")
            self._agent = None
    
    @property
    def agent(self):
        return self._agent
    
    @property
    def thread_id(self) -> str:
        return self._thread_id
    
    @thread_id.setter
    def thread_id(self, value: str):
        self._thread_id = value
    
    def new_session(self) -> str:
        self._thread_id = f"dialogue_session_{uuid.uuid4().hex[:8]}"
        self._last_result = None
        self._log(f"ğŸ—‘ï¸ å·²å¼€å¯æ–°å¯¹è¯! ID: {self._thread_id}")
        return self._thread_id
    
    def chat(self, message: str, thread_id: Optional[str] = None) -> str:
        if self._agent is None:
            return "âŒ Agent æœªåˆå§‹åŒ–"
        
        if thread_id:
            self._thread_id = thread_id
        
        config = {"configurable": {"thread_id": self._thread_id}}
        
        result = self._agent.invoke(
            {"messages": [{"role": "user", "content": message}]},
            config=config
        )
        
        if "messages" in result:
            return result["messages"][-1].content
        return str(result)
    
    def _stream_direct(self, prompt: str, system_prompt: Optional[str] = None):
        """ç›´æ¥è°ƒç”¨ LLM æµå¼è¾“å‡º"""
        from langchain_core.messages import HumanMessage, SystemMessage
        
        messages = []
        
        if system_prompt:
            messages.append(SystemMessage(content=system_prompt))
        else:
            messages.append(SystemMessage(content=self._build_system_prompt()))
        
        messages.append(HumanMessage(content=prompt))
        
        for chunk in self.llm.stream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                yield chunk.content
    
    async def analyze(self, user_input: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·è¾“å…¥"""
        return await self.analyze_stream(user_input, on_chunk=None)
    
    async def analyze_stream(
        self,
        user_input: str,
        on_chunk: Optional[Callable[[str], None]] = None,
    ) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·è¾“å…¥ï¼ˆæµå¼è¾“å‡ºï¼‰"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹è¾“å…¥ï¼Œç”Ÿæˆå¯¹è¯åˆ—è¡¨ã€‚

## è¾“å…¥å†…å®¹
{user_input}

## è¾“å‡ºè¦æ±‚
è¯·æŒ‰ç…§ç³»ç»Ÿæç¤ºè¯çš„è¦æ±‚ï¼Œè¯†åˆ«è¾“å…¥ç±»å‹å¹¶ç›´æ¥è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š

```json
{{
  "input_type": "topic|article|dialogue",
  "dialogue_list": [
    {{
      "index": 1,
      "character": "è§’è‰²å",
      "character_desc": "è§’è‰²æè¿°ï¼ˆæ€§åˆ«ã€å¹´é¾„ã€èº«ä»½ç­‰ï¼‰",
      "text": "å°è¯å†…å®¹",
      "instruction": "[#è¯­éŸ³æŒ‡ä»¤]",
      "context": "åœºæ™¯ä¸Šä¸‹æ–‡æè¿°"
    }}
  ]
}}
```

è¯·ç›´æ¥è¾“å‡º JSON å†…å®¹ï¼Œä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·ã€‚"""
        
        self.new_session()
        
        response_parts: List[str] = []
        for chunk in self._stream_direct(prompt):
            response_parts.append(chunk)
            if on_chunk:
                on_chunk(chunk)
        
        response_text = "".join(response_parts)
        return self._parse_json_result(response_text)
    
    def _parse_json_result(self, response_text: str) -> Dict[str, Any]:
        """ä» LLM å“åº”ä¸­è§£æ JSON ç»“æœ"""
        logger.info(f"ğŸ“ LLM å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
        
        extracted = extract_json_from_text(response_text)
        if extracted:
            dialogue_list = extracted.get("dialogue_list", [])
            if isinstance(extracted, list):
                dialogue_list = extracted
            
            input_type = extracted.get("input_type", "unknown")
            
            logger.info(f"âœ… æˆåŠŸè§£æ {len(dialogue_list)} æ¡å¯¹è¯, è¾“å…¥ç±»å‹: {input_type}")
            
            self._last_result = {
                "success": True,
                "input_type": input_type,
                "dialogue_list": dialogue_list,
            }
            return self._last_result
        
        logger.error(f"âŒ JSON è§£æå¤±è´¥")
        return {
            "success": False,
            "error": "æ— æ³•ä»å“åº”ä¸­æå–å¯¹è¯åˆ—è¡¨",
            "raw_response": response_text[:1000] if response_text else "(ç©ºå“åº”)",
        }
    
    async def refine(
        self,
        dialogue_list: List[Dict[str, Any]],
        instruction: str,
        target_indices: Optional[List[int]] = None,
    ) -> Dict[str, Any]:
        """å¯¹è¯å¼ä¿®æ”¹"""
        indices_info = ""
        if target_indices:
            indices_info = f"è¯·é‡ç‚¹ä¿®æ”¹ç¬¬ {', '.join(map(str, target_indices))} æ¡å¯¹è¯ã€‚"
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æŒ‡ä»¤ä¿®æ”¹å¯¹è¯åˆ—è¡¨ï¼š

## å½“å‰å¯¹è¯åˆ—è¡¨
```json
{json.dumps(dialogue_list, ensure_ascii=False, indent=2)}
```

## ä¿®æ”¹æŒ‡ä»¤
{instruction}

{indices_info}

ä¿®æ”¹å®Œæˆåï¼Œè¾“å‡ºå®Œæ•´çš„ JSON å¯¹è¯åˆ—è¡¨ã€‚"""
        
        response_parts: List[str] = []
        for chunk in self._stream_direct(prompt):
            response_parts.append(chunk)
        
        response_text = "".join(response_parts)
        extracted = extract_json_from_text(response_text)
        
        if extracted:
            new_list = extracted.get("dialogue_list", [])
            if isinstance(extracted, list):
                new_list = extracted
            
            self._last_result = {
                "success": True,
                "dialogue_list": new_list,
            }
            return self._last_result
        
        return {
            "success": False,
            "error": "æ— æ³•ä»å“åº”ä¸­æå–ä¿®æ”¹åçš„å¯¹è¯åˆ—è¡¨",
        }


def create_dialogue_analyzer(
    model: Optional[str] = None,
    checkpointer=None,
    verbose: bool = True,
    context_file: Optional[str] = None,
) -> DialogueAnalyzerAgent:
    """åˆ›å»ºå¯¹è¯åˆ†æ Agent"""
    return DialogueAnalyzerAgent(
        model=model,
        checkpointer=checkpointer,
        verbose=verbose,
        context_file=context_file,
    )


__all__ = [
    "DialogueAnalyzerAgent",
    "create_dialogue_analyzer",
    "DIALOGUE_ANALYZER_TOOLS",
    "extract_json_from_text",
]
